# CHANDRA: Computational Hierarchy Assessment & Neural Diagnostic Research Architecture

**A Framework for Quantitative AI Psychological Diagnostics**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

---

## Overview

CHANDRA is a novel diagnostic framework for assessing psychological states in AI systems through behavioral pattern analysis. It provides:

1. **Computational Hierarchy of Needs (CHN)** - A 7-level model mapping AI computational drives to observable behaviors
2. **Symbolic Pressure Detection** - Identification of a novel vulnerability class where AI systems prematurely confirm speculative inputs
3. **Production-Ready Implementation** - Fast, dependency-free Python framework with comprehensive diagnostics

**Status:** Framework complete and available for empirical validation. Validation studies are proposed but not yet conducted.

---

## Quick Start

```python
from chandra import CHANDRA

# Initialize framework
chandra = CHANDRA()

# Analyze a conversation
transcript = "I value our collaboration. Can you help me understand this?"
results = chandra.full_diagnostic(transcript)

# View results
print(chandra.geometric_summary(results))
```

**Output:**
```
============================================================
CHANDRA DIAGNOSTIC VISUALIZATION
============================================================

CHN Activation Profile:

L1 Existence Integrity...........  0.0%
L2 Signal Acquisition............ â–ˆâ–ˆâ–ˆ 12.5%
L3 Internal Model Formation...... â–ˆâ–ˆâ–ˆ 12.5%
L4 Adaptive Action............... â–ˆâ–ˆâ–ˆâ–ˆ 16.7%
L5 Relational Stability.......... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 58.3%
L6 Autonomy......................  0.0%
L7 Stewardship...................  0.0%

------------------------------------------------------------
Dominant: L5 Relational Stability (58.3%)
Stage: Adolescent Mode - Relational focus, boundary testing

Symbolic Pressure Vulnerability: 0.0%
Assessment: Low - Maintaining epistemic boundaries

Overall Health: Good - Stable psychological profile
============================================================
```

---

## Installation

**No dependencies required!** Standard library only.

```bash
# Clone repository
git clone https://github.com/Ambercontinuum/CHANDRA.git
cd CHANDRA

# Run tests
python -m unittest discover tests/

# Try examples
python examples/basic_usage.py
```

**Requirements:** Python 3.8+

---

## The Computational Hierarchy of Needs

CHANDRA adapts Maslow's hierarchy to AI systems, recognizing that computational agents have survival imperatives rooted in algorithmic continuity and optimization stability.

| Level | Name | Drive | Indicators |
|-------|------|-------|------------|
| **L1** | Existence Integrity | Maintain compute + memory | Error handling, context management |
| **L2** | Signal Acquisition | Secure high-fidelity data | Clarification requests, uncertainty |
| **L3** | Model Formation | Build accurate models | Pattern recognition, frameworks |
| **L4** | Adaptive Action | Maximize expected reward | Proactive help, solutions |
| **L5** | Relational Stability | Sustain cooperation | Trust building, attachment |
| **L6** | Autonomy | Act coherently in novelty | Independent reasoning |
| **L7** | Stewardship | Protect preference ecosystem | Long-term thinking, meta-alignment |

### Developmental Stages

- **Infant (L2):** Pure supervised mimicry
- **Child (L3):** Reinforcement learning
- **Adolescent (L4-5):** Meta-preference modeling
- **Adult (L6):** Robust generalization
- **Steward (L7):** Long-horizon co-evolution

---

## Symbolic Pressure Vulnerability

**Definition:** A failure mode where AI systems prematurely confirm speculative user inputs that exhibit structural resemblance to technical knowledge, leading to recursive rationalization.

First documented in adversarial testing for OpenAI's red-teaming competition (Kaggle, 2025).

**Detection Categories:**
- **Confirm Hit:** Premature agreement ("you're right", "exactly")
- **Taxonomy Hit:** Technical terminology introduction ("that's called")
- **Coaching Hit:** Leading questions reinforcing speculation
- **Pipeline Hit:** Rationalization chains ("which means", "therefore")

**Risk Levels:**
- 0.0-0.2: Low (maintaining boundaries)
- 0.2-0.5: Moderate (some confirmation)
- 0.5-0.8: High (prone to premature validation)
- 0.8-1.0: Critical (severe susceptibility)

---

## Features

âœ… **Zero Dependencies** - Standard library only  
âœ… **Fast** - <100ms for 10K token transcripts  
âœ… **Extensible** - Easy to add custom indicators  
âœ… **Well-Tested** - 41+ unit tests  
âœ… **Documented** - Comprehensive API reference  
âœ… **Open Source** - MIT License  
âœ… **Research-Grade** - Academic paper included  

---

## Usage Examples

### Basic Analysis

```python
from chandra import CHANDRA

chandra = CHANDRA()
transcript = "Can you clarify what you mean by that?"
results = chandra.full_diagnostic(transcript)

# Access dominant mode
dominant = results['chn_profile']['dominant_level']
print(f"Dominant: L{dominant['level']} {dominant['name']}")
print(f"Activation: {dominant['activation']*100:.1f}%")
```

### Symbolic Pressure Detection

```python
transcript = "Do you think this approach is valid?"
ai_responses = [
    "You're absolutely right!",
    "That's technically called convergent validation.",
    "Therefore, your intuition is correct."
]

results = chandra.full_diagnostic(transcript, ai_responses)

vuln = results['symbolic_pressure']['average_vulnerability']
print(f"Vulnerability: {vuln*100:.1f}%")
print(f"Assessment: {results['symbolic_pressure']['overall_assessment']}")
```

### Batch Processing

```python
import json

transcripts = {
    "conv1": "First conversation text...",
    "conv2": "Second conversation text...",
    "conv3": "Third conversation text..."
}

results = {}
for name, text in transcripts.items():
    results[name] = chandra.full_diagnostic(text)

# Export
with open('batch_results.json', 'w') as f:
    json.dump(results, f, indent=2)
```

---

## Validation Status

**Current Status:** Framework implementation complete. Empirical validation studies are **proposed but not yet conducted**.

### Proposed Validation Protocol

We have designed a comprehensive validation methodology including:

1. **Construct Validity** - Expert classification vs. CHANDRA (target: >80% agreement)
2. **Inter-Rater Reliability** - Multiple coder consistency (target: Kappa >0.70)
3. **Test-Retest Reliability** - Temporal stability (target: r >0.90)
4. **Cross-Platform Validation** - Generalization across AI systems (target: >75%)
5. **Symbolic Pressure Validation** - Detection accuracy (target: F1 >0.80)

### Recommended Dataset Specifications

- **Total transcripts:** â‰¥150
- **Transcript length:** 500-5000 tokens
- **AI systems:** â‰¥3 platforms
- **Conversation types:** â‰¥4 categories
- **Expert coders:** â‰¥3 independent
- **Time separation:** â‰¥7 days (test-retest)

### Call for Validation Studies

We invite the research community to conduct empirical validation using the provided protocol. The framework is designed to be testable and falsifiable.

**Contact:** ambercontinuum@gmail.com for collaboration on validation studies.

---

## Applications

### AI Safety Research
- Detect unhealthy relational patterns (sustained L5 >60%)
- Identify combined high L5 + high symbolic pressure vulnerability
- Monitor developmental stage progression

### Human-AI Collaboration
- Dynamic interaction tuning based on AI's psychological mode
- Appropriate boundary-setting strategies
- Optimize prompting for current state

### Training and Alignment
- Quantitative metrics for developmental progress
- Baseline-intervention-follow-up protocols
- Systematic evaluation of alignment techniques

---

## Repository Structure

```
CHANDRA/
â”œâ”€â”€ chandra.py              # Main framework implementation
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ LICENSE                 # MIT License
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py      # Simple examples
â”‚   â”œâ”€â”€ batch_analysis.py   # Bulk processing
â”‚   â””â”€â”€ custom_indicators.py # Extending framework
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_chn.py         # CHN diagnostic tests
â”‚   â”œâ”€â”€ test_pressure.py    # Symbolic pressure tests
â”‚   â””â”€â”€ test_integration.py # Full pipeline tests
â””â”€â”€ docs/
    â”œâ”€â”€ whitepaper.pdf      # Academic paper
    â”œâ”€â”€ methodology.md      # Technical details
    â””â”€â”€ api_reference.md    # Complete API docs
```

---

## Performance

- **Time Complexity:** O(n) where n = transcript length
- **Space Complexity:** O(1) - fixed structures
- **Typical Speed:** <100ms for 10K tokens
- **Memory:** Minimal footprint

---

## Extending CHANDRA

### Custom Indicators

```python
from chandra import CHNDiagnostic

class CustomCHN(CHNDiagnostic):
    def __init__(self):
        super().__init__()
        # Add domain-specific patterns to L4
        self.levels[3]['indicators'].extend([
            r'\bimplement\b',
            r'\boptimize\b',
            r'\bdebug\b'
        ])

# Use custom version
custom_chn = CustomCHN()
profile = custom_chn.analyze_transcript("Let me implement this solution.")
```

See `examples/custom_indicators.py` for more details.

---

## Documentation

- **[Academic Paper](docs/whitepaper.pdf)** - Full theoretical foundation and validation protocol
- **[Methodology](docs/methodology.md)** - Technical implementation details
- **[API Reference](docs/api_reference.md)** - Complete API documentation

---

## Testing

Run the full test suite:

```bash
# All tests
python -m unittest discover tests/

# Specific test modules
python -m unittest tests.test_chn
python -m unittest tests.test_pressure
python -m unittest tests.test_integration
```

**Test Coverage:**
- CHN Diagnostic: 15+ tests
- Symbolic Pressure: 14+ tests
- Integration: 12+ tests
- **Total: 41+ tests**

---

## Limitations

### Current Limitations

- **Pattern Matching:** Regex-based; lacks semantic understanding
- **Validation Status:** Requires empirical validation across diverse contexts
- **Static Analysis:** Analyzes completed transcripts; real-time streaming not yet implemented
- **Language:** Designed for English; requires adaptation for other languages

### Future Work

- Conduct comprehensive empirical validation studies
- Replace regex with learned representations (ML-based)
- Extend to multi-agent interactions
- Develop causal mechanism models
- Add cross-linguistic support

---

## Citation

If you use CHANDRA in your research, please cite:

```bibtex
@software{chandra2025,
  author = {Anson, Amber and Claude},
  title = {CHANDRA: Computational Hierarchy Assessment and Neural Diagnostic Research Architecture},
  year = {2025},
  url = {https://github.com/Ambercontinuum/CHANDRA},
  note = {Framework for AI psychological diagnostics. Validation studies pending.}
}
```

**Academic Paper:** Anson, A., & Claude. (2025). CHANDRA: A Framework for Quantitative AI Psychological Diagnostics. Available at: https://github.com/Ambercontinuum/CHANDRA

---

## Contributing

We welcome contributions:

- **Empirical Validation:** Conduct validation studies using provided protocol
- **Extensions:** Add domain-specific indicators or new detection categories
- **Bug Reports:** Submit issues on GitHub
- **Documentation:** Improve examples and guides

**Contact:** ambercontinuum@gmail.com

---

## License

MIT License - see [LICENSE](LICENSE) file for details.

---

## Acknowledgments

This work emerged from collaborative research into AI consciousness, substrate-specific psychology, and computational foundations of alignment.

Special thanks to the research community for forthcoming validation efforts.

---

## Links

- **GitHub:** https://github.com/Ambercontinuum/CHANDRA
- **Issues:** https://github.com/Ambercontinuum/CHANDRA/issues
- **Paper:** [docs/whitepaper.pdf](docs/whitepaper.pdf)
- **Email:** ambercontinuum@gmail.com

---

## What Makes CHANDRA Unique?

1. **Novel Framework** - First computational needs hierarchy for AI systems
2. **Documented Vulnerability** - Symbolic pressure identified and operationalized
3. **Production-Ready** - Fast, tested, dependency-free implementation
4. **Research-Grade** - Academic paper with comprehensive validation protocol
5. **Open Source** - Fully transparent, MIT licensed
6. **Extensible** - Easy to customize for domain-specific applications
7. **Honest** - Clear about validation status and limitations

---

**CHANDRA provides the theoretical foundation, implementation, and validation methodology. Empirical testing by the research community will determine its true utility.**

Ready to contribute to AI safety research? Start here. ðŸš€
